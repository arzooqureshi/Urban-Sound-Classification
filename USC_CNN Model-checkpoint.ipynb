{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGa7UiWyQgUt"
   },
   "outputs": [],
   "source": [
    "mfccs=[]\n",
    "for i in range(len(train[:10])):\n",
    "  file_name='/content/drive/My Drive/BTP_DATA/train/Train/' + str(train.ID[i+100]) + '.wav'\n",
    "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "  mfccs.append(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "bWHGe_PaQxfW",
    "outputId": "d1d489fe-d20a-4f2c-830a-bce46f06910f"
   },
   "outputs": [],
   "source": [
    "for i in range(len(mfccs)):\n",
    "  print(len(mfccs[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "041wvTpGQ3XZ",
    "outputId": "b8120ea4-ce9c-4fed-ebfb-7f3304c086e2"
   },
   "outputs": [],
   "source": [
    "max_pad_len=174 # I am defining a maximum length for each column \n",
    "\n",
    "file_name='/content/drive/My Drive/BTP_DATA/train/Train/12.wav'\n",
    "audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "mfcc=librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "print('Shape of feature matrix: ',mfcc.shape)\n",
    "pad_width = max_pad_len - mfcc.shape[1]\n",
    "print('Pad width: ',pad_width)\n",
    "mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "print('Shape of feature matrix after padding: ',mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwReam4PRDUc"
   },
   "outputs": [],
   "source": [
    "features_new=[]\n",
    "labels=[]\n",
    "max_pad_len=174 \n",
    "\n",
    "for i in range(len(train)):\n",
    "  filename='/content/drive/My Drive/BTP_DATA/train/Train/' + str(train.ID[i]) + '.wav'\n",
    "  x, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "  mfcc=librosa.feature.mfcc(y=x, sr=sample_rate, n_mfcc=40)\n",
    "  pad_width = max_pad_len - mfcc.shape[1]\n",
    "  mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "  features_new.append(mfcc)\n",
    "  labels.append(train.Class[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJVuBaSrWFUH"
   },
   "outputs": [],
   "source": [
    "features_new_test=[]\n",
    "max_pad_len=174 \n",
    "\n",
    "for i in range(len(test)):\n",
    "  filename='/content/drive/My Drive/BTP_DATA/test/Test/' + str(test.ID[i]) + '.wav'\n",
    "  x, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "  mfcc=librosa.feature.mfcc(y=x, sr=sample_rate, n_mfcc=40)\n",
    "  pad_width = max_pad_len - mfcc.shape[1]\n",
    "  mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "  features_new_test.append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dqjsQEeZ5d9"
   },
   "outputs": [],
   "source": [
    "x_new=np.array(features_new)  #coverting the features vector to a numpy array\n",
    "x_new=x_new.reshape(x_new.shape[0], 40, 174, 1) #reshaping the array for the convolution layer input\n",
    "\n",
    "x_new_test=np.array(features_new_test)  \n",
    "x_new_test=x_new_test.reshape(x_new_test.shape[0], 40, 174, 1)\n",
    "\n",
    "#encoding the labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = to_categorical(le.fit_transform(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "4xD5o5f9aCux",
    "outputId": "a423d9ca-380b-4db9-9322-22546dd98a35"
   },
   "outputs": [],
   "source": [
    "print('Shape of Features(Train): ',x_new.shape)\n",
    "print('Shape of Features(Test): ',x_new_test.shape)\n",
    "print('Shape of Labels(Train): ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ycRXuBv6aKkp"
   },
   "outputs": [],
   "source": [
    "model2=tf.keras.models.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(40,174,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(256,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WYsGzlyoaS68",
    "outputId": "76cb01d4-5896-4dbb-c91e-a144ad2e7385"
   },
   "outputs": [],
   "source": [
    "\n",
    "reduce =tf. keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode='auto')\n",
    "#early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, mode='auto')\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history2=model2.fit(x_new,y, batch_size=32, epochs=100, validation_split=0.1,callbacks=[reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "w6o6-g7ylqsF",
    "outputId": "30f6ea35-b43c-426d-d117-3dcc87317dce"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "acc=history2.history['accuracy']\n",
    "val_acc=history2.history['val_accuracy']\n",
    "loss=history2.history['loss']\n",
    "val_loss=history2.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) #No. of epochs\n",
    "\n",
    "#Plot training and validation accuracy per epoch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochs,acc,'b',label='Training Accuracy')\n",
    "plt.plot(epochs,val_acc,'r',label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "#Plot training and validation loss per epoch\n",
    "plt.plot(epochs,loss,'b',label='Training Loss')\n",
    "plt.plot(epochs,val_loss,'r',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNlExBcGl0_U"
   },
   "outputs": [],
   "source": [
    "pred2=model2.predict(x_new_test)\n",
    "b=np.argmax(pred2,axis=1)\n",
    "pred_test2=le.inverse_transform(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSfQddrpnNpm"
   },
   "outputs": [],
   "source": [
    "ut_df = pd.DataFrame({'ID':test['ID'].values})\n",
    "out_df .insert(loc=0, column='class_test', value=pred_test2)\n",
    "out_df.to_csv('/content/drive/My Drive/BTP_DATA/submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYHhYf5roDTQ"
   },
   "outputs": [],
   "source": [
    "model2.save(\"/content/drive/My Drive/BTP_DATA/train/model2.h5\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Btech Presentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
